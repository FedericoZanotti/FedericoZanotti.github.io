---
layout: post
title: Restriced Boltzmann Machine experiments
subtitle: Different testing of RBMs and DBNs on EMNIST Dataset
thumbnail-img: /assets/img/featured.png
gh-badge: [star, fork, follow]
tags: [RBM, DBN, Python, EMNIST]
comments: true
---

# RBMs and DBNs

**Source Code**: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FedericoZanotti/RBM-analysis/blob/master/CC_final_project.ipynb)

In this project I tested different configuration of **Restriced Boltzmann Machine (RBM)** and its deep version, **Deep Belief Network (DBN)**, composed by stacked layer
of RBMs. These models are called generative model and they try to capture the manifold of the data by learning the probability distribution of the
input in an unsupervised way.
The generative models enable to automatically uncover underlying features of the data that humans don't
are aware of them. We don't know how we recognize a digit or a letter, we just know from our experience
without even thinking about it. The RBMs instead have no experience and so they learn that images of
digits and letters are composed by edges, that can be combined in different way in order to create more
different examples.
All the experiments were made with on a popular dataset for Machine
Learning: **EMNIST**.

All the results and information are describe in this [report](https://github.com/FedericoZanotti/RBM-analysis/blob/main/Federico Zanotti Essay.pdf)


